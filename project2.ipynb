{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "## Web Information Management: Project II #\n",
    "In this project, I will develop different algorithms to make recommendations for movies.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and export functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "UPDATE_INT = 10\n",
    "\n",
    "def fetch_train():\n",
    "    data = pd.read_csv('data/train.txt', delimiter='\\t', header=None, dtype=int)\n",
    "    return data\n",
    "\n",
    "def fetch_test(fn):\n",
    "    data = pd.read_csv('data/'+fn, delimiter=' ', header=None, names=['U','M','R'], dtype=int)\n",
    "    return data\n",
    "\n",
    "def write_test(data, fn):\n",
    "    data.to_csv('result/'+fn, sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zeros(a, b):\n",
    "    assert len(a)==len(b)\n",
    "    ra = np.array([])\n",
    "    rb = np.array([])\n",
    "    for x1, x2 in zip(a,b):\n",
    "        if x1 and x2:\n",
    "            ra = np.append(ra, x1)\n",
    "            rb = np.append(rb, x2)\n",
    "    return ra, rb\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    assert a.shape == b.shape, \"{} != {}\".format(a.shape, b.shape)\n",
    "    if np.sum(b)==0:\n",
    "        return 0\n",
    "    \n",
    "    # remove 0's\n",
    "    ta, tb = remove_zeros(a, b)\n",
    "    if len(ta)<2 or len(tb)<2:\n",
    "        return 0\n",
    "    \n",
    "    # cosine similarity\n",
    "    num = ta.dot(tb)\n",
    "    den = np.linalg.norm(ta)*np.linalg.norm(tb)\n",
    "    return num/den\n",
    "\n",
    "def pea_cor(a, b):\n",
    "    assert a.shape == b.shape, \"{} != {}\".format(a.shape, b.shape)\n",
    "    \n",
    "    # remove 0's\n",
    "    ta, tb = remove_zeros(a, b)\n",
    "    \n",
    "    # remove 1 element arrays?\n",
    "    if len(ta)<2 or len(tb)<2:\n",
    "        return 0\n",
    "    \n",
    "    # subtract average\n",
    "    ta = ta - np.mean(ta)\n",
    "    tb = tb - np.mean(tb)\n",
    "    \n",
    "    # cosine similarity\n",
    "    num = ta.dot(tb)\n",
    "    den = np.linalg.norm(ta)*np.linalg.norm(tb)\n",
    "    return (num/den) if den else 0\n",
    "\n",
    "def weighted_avg(w, r, absval=False):\n",
    "    assert w.shape == r.shape, \"{} != {}\".format(w.shape, r.shape)\n",
    "    if np.sum(w) == 0:\n",
    "        return 0\n",
    "    if absval:\n",
    "        return np.sum(w*r)/np.sum(np.absolute(w))\n",
    "    return np.sum(w*r)/np.sum(w)\n",
    "\n",
    "def count_col(arr, target, column):\n",
    "    for t in target:\n",
    "        count = arr[arr[column]==t].count()\n",
    "        print(\"! {} appears {} times in column {}\".format(t, count[column], column))\n",
    "    return 0\n",
    "\n",
    "def constrain_array(arr, lower=1, upper=5):\n",
    "    arr[arr<lower] = lower\n",
    "    arr[arr>upper] = upper\n",
    "    count_col(arr, [lower-1, upper+1], 'R')\n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Functions:\n",
    "> Here, I implemented several user-based collaborative filtering algorithms, including modifications such as cosine similarity, Pearson correlation, inverse user frequency, and case modification.\n",
    "- Cosine Similarity\n",
    "- Pearson Correlation\n",
    "- Pearson Correlation w/ Inverse User Frequency\n",
    "- Pearson Correlation w/ Case Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cosine Similarity\n",
    "def problem2_cs(testfile, outfile=None):\n",
    "    \n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    \n",
    "    # create rng, a list of users to solve for\n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    # loop through each user\n",
    "    for i in range(rng[0], rng[1]):\n",
    "        \n",
    "        # separate known and nuknown ratings\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        # calculate USER similarity by comparing each rating R in 'known' against every other movie rating\n",
    "        user_sim = train.apply(lambda x: cos_sim(known.R.values, x[known.M].values), axis=1)\n",
    "        \n",
    "        # separate relevant values and users\n",
    "        user_sim_sort = user_sim.sort_values(ascending=False)\n",
    "        rel_vals = user_sim[user_sim>0]\n",
    "        rel_users = rel_vals.index.values\n",
    "        \n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rel_ratings = train.iloc[rel_users, r.M-1]\n",
    "            rv, rr = remove_zeros(rel_vals.values, rel_ratings.values)\n",
    "            if len(rv) and len(rr):\n",
    "                r.R = round(weighted_avg(rv, rr))\n",
    "            else:\n",
    "                r.R = 3\n",
    "            \n",
    "        results = pd.concat([results,unknown], ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "            \n",
    "    constrain_array(results)\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results, outfile)\n",
    "        print('> Results written to {}\\n'.format(outfile))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Pearson Correlation\n",
    "def problem2_pc(testfile, outfile=None):\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    \n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    for i in range(rng[0], rng[1]):\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        similarity = train.apply(lambda x: pea_cor(known.R.values, x[known.M].values), axis=1)\n",
    "        \n",
    "        rel_vals = similarity[similarity!=0]\n",
    "        rel_users = rel_vals.index.values\n",
    "        \n",
    "        avg_rating = np.mean(known.R)\n",
    "        \n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rel_ratings = train.iloc[rel_users, r.M-1]\n",
    "            rel_ratings = rel_ratings - np.mean(rel_ratings)\n",
    "            rv, rr = remove_zeros(rel_vals.values, rel_ratings.values)\n",
    "            if len(rv) and len(rr):\n",
    "                r.R = round(avg_rating + weighted_avg(rv, rr, True))\n",
    "            else:\n",
    "                r.R = round(avg_rating)\n",
    "            \n",
    "        results = pd.concat([results,unknown], ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "    \n",
    "    constrain_array(results)\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results, outfile)\n",
    "        print('> Results written to {}\\n'.format(outfile))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Pearson Correlation w/ Inverse User Frequency\n",
    "def problem2_pciuf(testfile, outfile=None):\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    \n",
    "    m = len(train)\n",
    "    iuf = []\n",
    "    for i,c in train.iteritems():\n",
    "        mj = c[c!=0].count()\n",
    "        iuf.append(np.log(m/mj) if mj else 0.0)\n",
    "    train_iuf = train*iuf\n",
    "    \n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    for i in range(rng[0], rng[1]):\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        similarity = train_iuf.apply(lambda x: pea_cor(known.R.values, x[known.M].values), axis=1)\n",
    "        \n",
    "        rel_vals = similarity[similarity!=0]\n",
    "        rel_users = rel_vals.index.values\n",
    "        \n",
    "        avg_rating = np.mean(known.R)\n",
    "        \n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rel_ratings = train.iloc[rel_users, r.M-1]\n",
    "            rel_ratings = rel_ratings - np.mean(rel_ratings)\n",
    "            rv, rr = remove_zeros(rel_vals.values, rel_ratings.values)\n",
    "            if len(rv) and len(rr):\n",
    "                r.R = round(avg_rating + weighted_avg(rv, rr, True))\n",
    "            else:\n",
    "                r.R = round(avg_rating)\n",
    "            \n",
    "        results = pd.concat([results,unknown], ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "        \n",
    "    constrain_array(results)\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results, outfile)\n",
    "        print('> Results written to {}\\n'.format(outfile))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Pearson Correlation w/ Case Modification\n",
    "def problem2_pccm(testfile, outfile=None):\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    \n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    for i in range(rng[0], rng[1]):\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        similarity = train.apply(lambda x: pea_cor(known.R.values, x[known.M].values), axis=1)\n",
    "        \n",
    "        rel_vals = similarity[similarity!=0]\n",
    "        rel_users = rel_vals.index.values\n",
    "        \n",
    "        avg_rating = np.mean(known.R)\n",
    "        \n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rel_ratings = train.iloc[rel_users, r.M-1]\n",
    "            rel_ratings = rel_ratings - np.mean(rel_ratings)\n",
    "            rv, rr = remove_zeros(rel_vals.values, rel_ratings.values)\n",
    "            if len(rv) and len(rr):\n",
    "                r.R = round(avg_rating + weighted_avg(rv, rr, True))\n",
    "            else:\n",
    "                r.R = round(avg_rating)\n",
    "            \n",
    "        results = pd.concat([results,unknown], ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "        \n",
    "    constrain_array(results)\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results, outfile)\n",
    "        print('> Results written to {}\\n'.format(outfile))\n",
    "        \n",
    "    return results\n",
    "\n",
    "# should k be same value every time?\n",
    "# should i remove cases with only 1 rating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Function:\n",
    "> Here I implemented a basic item-based collaborative filtering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem3(testfile, outfile=None):\n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    \n",
    "    # create rng, a list of users to solve for\n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    unknown = test[test.R==0]\n",
    "    ct = 0\n",
    "    \n",
    "    # iterate through all unranked movies\n",
    "    for i,r in unknown.iterrows():\n",
    "        known = test[(test.R!=0) & (test.U==r.U)]\n",
    "        \n",
    "        # generate the ITEM similarity matrix (using cos_sim)\n",
    "        item_sim = train[known.M].apply(lambda x: cos_sim(train[r.M-1], x), axis=0)\n",
    "        \n",
    "        # sort the similarity matrix in descending order\n",
    "        item_sim_sort = item_sim.sort_values(ascending=False)\n",
    "        \n",
    "        # compute ratings\n",
    "        r.R = round(weighted_avg(item_sim[known.M], known.R))\n",
    "             \n",
    "        results = pd.concat([results,unknown], ignore_index=True)\n",
    "        \n",
    "        # progress update\n",
    "        ct = ct + 1\n",
    "        if ct%100 == 0:\n",
    "            print(\"Completed {} iterations... (known {})\".format(ct, known.shape))\n",
    "            \n",
    "    count_col(results, [0, 6], 'R')\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results, outfile)\n",
    "        print('> Results written to {}\\n'.format(outfile))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Function:\n",
    "> This is a personal algorithm I created to try to achieve better MAE than the previous methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and exporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 210 (19 predictions)...\n",
      "User 220 (19 predictions)...\n",
      "User 230 (43 predictions)...\n",
      "User 240 (28 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 260 (39 predictions)...\n",
      "User 270 (37 predictions)...\n",
      "User 280 (37 predictions)...\n",
      "User 290 (36 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_cs.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test01 = problem2_cs('test5.txt', 'result5_cs.txt')\n",
    "# test02 = problem2_cs('test10.txt', 'result10_cs.txt')\n",
    "# test03 = problem2_cs('test20.txt', 'result20_cs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 210 (19 predictions)...\n",
      "User 220 (19 predictions)...\n",
      "User 230 (43 predictions)...\n",
      "User 240 (28 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 260 (39 predictions)...\n",
      "User 270 (37 predictions)...\n",
      "User 280 (37 predictions)...\n",
      "User 290 (36 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_pc.txt\n",
      "\n",
      "User 310 (7 predictions)...\n",
      "User 320 (11 predictions)...\n",
      "User 330 (11 predictions)...\n",
      "User 340 (134 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 360 (9 predictions)...\n",
      "User 370 (42 predictions)...\n",
      "User 380 (28 predictions)...\n",
      "User 390 (78 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_pc.txt\n",
      "\n",
      "User 410 (5 predictions)...\n",
      "User 420 (58 predictions)...\n",
      "User 430 (85 predictions)...\n",
      "User 440 (60 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 460 (257 predictions)...\n",
      "User 470 (291 predictions)...\n",
      "User 480 (76 predictions)...\n",
      "User 490 (75 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_pc.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test04 = problem2_pc('test5.txt', 'result5_pc.txt')\n",
    "test05 = problem2_pc('test10.txt', 'result10_pc.txt')\n",
    "test06 = problem2_pc('test20.txt', 'result20_pc.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 210 (19 predictions)...\n",
      "User 220 (19 predictions)...\n",
      "User 230 (43 predictions)...\n",
      "User 240 (28 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 260 (39 predictions)...\n",
      "User 270 (37 predictions)...\n",
      "User 280 (37 predictions)...\n",
      "User 290 (36 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_pciuf.txt\n",
      "\n",
      "User 310 (7 predictions)...\n",
      "User 320 (11 predictions)...\n",
      "User 330 (11 predictions)...\n",
      "User 340 (134 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 360 (9 predictions)...\n",
      "User 370 (42 predictions)...\n",
      "User 380 (28 predictions)...\n",
      "User 390 (78 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_pciuf.txt\n",
      "\n",
      "User 410 (5 predictions)...\n",
      "User 420 (58 predictions)...\n",
      "User 430 (85 predictions)...\n",
      "User 440 (60 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 460 (257 predictions)...\n",
      "User 470 (291 predictions)...\n",
      "User 480 (76 predictions)...\n",
      "User 490 (75 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_pciuf.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test07 = problem2_pciuf('test5.txt', 'result5_pciuf.txt')\n",
    "test08 = problem2_pciuf('test10.txt', 'result10_pciuf.txt')\n",
    "test09 = problem2_pciuf('test20.txt', 'result20_pciuf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 210 (19 predictions)...\n",
      "User 220 (19 predictions)...\n",
      "User 230 (43 predictions)...\n",
      "User 240 (28 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 260 (39 predictions)...\n",
      "User 270 (37 predictions)...\n",
      "User 280 (37 predictions)...\n",
      "User 290 (36 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_pccm.txt\n",
      "\n",
      "User 310 (7 predictions)...\n",
      "User 320 (11 predictions)...\n",
      "User 330 (11 predictions)...\n",
      "User 340 (134 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 360 (9 predictions)...\n",
      "User 370 (42 predictions)...\n",
      "User 380 (28 predictions)...\n",
      "User 390 (78 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_pccm.txt\n",
      "\n",
      "User 410 (5 predictions)...\n",
      "User 420 (58 predictions)...\n",
      "User 430 (85 predictions)...\n",
      "User 440 (60 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 460 (257 predictions)...\n",
      "User 470 (291 predictions)...\n",
      "User 480 (76 predictions)...\n",
      "User 490 (75 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_pccm.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test10 = problem2_pccm('test5.txt', 'result5_pccm.txt')\n",
    "test11 = problem2_pccm('test10.txt', 'result10_pccm.txt')\n",
    "test12 = problem2_pccm('test20.txt', 'result20_pccm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 iterations... (known (5, 3))\n",
      "Completed 200 iterations... (known (5, 3))\n",
      "Completed 300 iterations... (known (5, 3))\n",
      "Completed 400 iterations... (known (5, 3))\n",
      "Completed 500 iterations... (known (5, 3))\n",
      "Completed 600 iterations... (known (5, 3))\n",
      "Completed 700 iterations... (known (5, 3))\n",
      "Completed 800 iterations... (known (5, 3))\n",
      "Completed 900 iterations... (known (5, 3))\n",
      "Completed 1000 iterations... (known (5, 3))\n",
      "Completed 1100 iterations... (known (5, 3))\n",
      "Completed 1200 iterations... (known (5, 3))\n",
      "Completed 1300 iterations... (known (5, 3))\n",
      "Completed 1400 iterations... (known (5, 3))\n",
      "Completed 1500 iterations... (known (5, 3))\n",
      "Completed 1600 iterations... (known (5, 3))\n",
      "Completed 1700 iterations... (known (5, 3))\n",
      "Completed 1800 iterations... (known (5, 3))\n",
      "Completed 1900 iterations... (known (5, 3))\n",
      "Completed 2000 iterations... (known (5, 3))\n",
      "Completed 2100 iterations... (known (5, 3))\n",
      "Completed 2200 iterations... (known (5, 3))\n",
      "Completed 2300 iterations... (known (5, 3))\n",
      "Completed 2400 iterations... (known (5, 3))\n",
      "Completed 2500 iterations... (known (5, 3))\n",
      "Completed 2600 iterations... (known (5, 3))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e48ac0d42c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest13\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproblem3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test5.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result5_ibcf.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# test14 = problem3('test10.txt', 'result10_ibcf.txt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# test15 = problem3('test20.txt', 'result20_ibcf.txt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-1a456584fd2a>\u001b[0m in \u001b[0;36mproblem3\u001b[0;34m(testfile, outfile)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# progress update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Completed {} iterations... (known {})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test13 = problem3('test5.txt', 'result5_ibcf.txt')\n",
    "# test14 = problem3('test10.txt', 'result10_ibcf.txt')\n",
    "# test15 = problem3('test20.txt', 'result20_ibcf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIN: 9423572820721098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
