{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System\n",
    "## Web Information Management: Project II #\n",
    "In this project, I will develop different algorithms to make recommendations for movies.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import and export functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "UPDATE_INT = 25\n",
    "\n",
    "def fetch_train():\n",
    "    data = pd.read_csv('data/train.txt', delimiter='\\t', header=None, names=np.arange(1, 1001), dtype=int)\n",
    "    return data\n",
    "\n",
    "def fetch_test(fn):\n",
    "    data = pd.read_csv('data/'+fn, delimiter=' ', header=None, names=['U','M','R'], dtype=int)\n",
    "    return data\n",
    "\n",
    "def write_test(data, fn):\n",
    "    data.to_csv('result/'+fn, sep=' ', header=False, index=False)\n",
    "    print('> Results written to {}\\n'.format(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zeros(a, b):\n",
    "    assert len(a)==len(b), \"{} != {}\".format(len(a), len(b))\n",
    "    ra = np.array([])\n",
    "    rb = np.array([])\n",
    "    for x1, x2 in zip(a,b):\n",
    "        if x1 and x2:\n",
    "            ra = np.append(ra, x1)\n",
    "            rb = np.append(rb, x2)\n",
    "    return ra, rb\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    assert a.shape == b.shape, \"{} != {}\".format(a.shape, b.shape)\n",
    "    if np.sum(b)==0:\n",
    "        return 0\n",
    "    \n",
    "    # remove 0's\n",
    "    ta, tb = remove_zeros(a, b)\n",
    "    if len(ta)<2 or len(tb)<2:\n",
    "        return 0\n",
    "    \n",
    "    # cosine similarity\n",
    "    num = ta.dot(tb)\n",
    "    den = np.linalg.norm(ta)*np.linalg.norm(tb)\n",
    "    return num/den\n",
    "\n",
    "def pea_cor(a, b):\n",
    "    assert a.shape == b.shape, \"{} != {}\".format(a.shape, b.shape)\n",
    "    \n",
    "    # remove 0's\n",
    "    ta, tb = remove_zeros(a, b)\n",
    "    \n",
    "    # remove 1 element arrays?\n",
    "    if len(ta)<2 or len(tb)<2:\n",
    "        return 0\n",
    "    \n",
    "    # subtract average\n",
    "    ta = ta - np.mean(ta)\n",
    "    tb = tb - np.mean(tb)\n",
    "    \n",
    "    # cosine similarity\n",
    "    num = ta.dot(tb)\n",
    "    den = np.linalg.norm(ta)*np.linalg.norm(tb)\n",
    "    return (num/den) if den else 0\n",
    "\n",
    "def weighted_avg(w, r, absval=False):\n",
    "    assert w.shape == r.shape, \"{} != {}\".format(w.shape, r.shape)\n",
    "    if np.sum(w) == 0:\n",
    "        return 0\n",
    "    if absval:\n",
    "        return np.sum(w*r)/np.sum(np.absolute(w))\n",
    "    return np.sum(w*r)/np.sum(w)\n",
    "\n",
    "def count_col(arr, target, column):\n",
    "    for t in target:\n",
    "        count = arr[arr[column]==t].count()\n",
    "        print(\"! {} appears {} times in column {}\".format(t, count[column], column))\n",
    "    return 0\n",
    "\n",
    "def round_result(val, lower=1, upper=5):\n",
    "    if val == 0:\n",
    "        return (upper+lower)/2\n",
    "    elif val < lower:\n",
    "        return lower\n",
    "    elif val > upper:\n",
    "        return upper\n",
    "    else:\n",
    "        return round(val)\n",
    "\n",
    "def constrain_array(arr, col, lower=1, upper=5):\n",
    "    arr[arr[col]<lower] = lower\n",
    "    arr[arr[col]>upper] = upper\n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Functions:\n",
    "Here, I implemented several user-based collaborative filtering algorithms, including modifications such as cosine similarity, Pearson correlation, inverse user frequency, and case modification.\n",
    "- Cosine Similarity\n",
    "- Pearson Correlation\n",
    "- Pearson Correlation w/ Inverse User Frequency\n",
    "- Pearson Correlation w/ Case Modification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Cosine Similarity\n",
    "> Using cosine similarity, the user similarity is calculated using the following formula:\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\cos\\theta = \\frac{\\vec{A} \\cdot \\vec{B}}{||\\vec{A}|| \\times ||\\vec{B}||}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 225 (140 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 275 (7 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_cs.txt\n",
      "\n",
      "User 325 (12 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 375 (19 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_cs.txt\n",
      "\n",
      "User 425 (94 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 475 (86 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_cs.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Cosine Similarity\n",
    "def problem2_cs(testfile, outfile=None, k=None, t=0.8):\n",
    "    \n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    test['R2'] = 0.0\n",
    "    \n",
    "    # create rng, a list of users to solve for\n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    # loop through each user\n",
    "    for i in range(rng[0], rng[1]):\n",
    "        \n",
    "        # separate known and unknown ratings\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        # calculate USER similarity by comparing each rating R in 'known' against every other movie rating\n",
    "        user_sim = train.apply(lambda x: cos_sim(known.R.values, x[known.M].values), axis=1)\n",
    "\n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rs, rr = remove_zeros(user_sim, train[r.M])\n",
    "            knn = pd.DataFrame({'S':rs, 'R':rr}).sort_values(by='S', ascending=False)\n",
    "            knn = knn.iloc[:k]\n",
    "            r.R2 = weighted_avg(knn['S'], knn['R'])\n",
    "            r.R = round_result(r.R2)\n",
    "            \n",
    "            results = results.append(r, ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "    \n",
    "    # remove 0's and 6's\n",
    "    count_col(results, [0,6], 'R')\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results[['U','M','R']].astype(int), outfile)\n",
    "        \n",
    "    return results\n",
    "\n",
    "test01 = problem2_cs('test5.txt', 'result5_cs.txt')\n",
    "test02 = problem2_cs('test10.txt', 'result10_cs.txt')\n",
    "test03 = problem2_cs('test20.txt', 'result20_cs.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Pearson Correlation\n",
    "> Using pearson correlation, the user similarity is calculated using the following formula:\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "\\cos\\theta = \\frac{(A-\\overline{A}) \\cdot (B-\\overline{B})}{||(A-\\overline{A})|| \\times ||(B-\\overline{B})||}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 225 (140 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 275 (7 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_pc.txt\n",
      "\n",
      "User 325 (12 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 375 (19 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_pc.txt\n",
      "\n",
      "User 425 (94 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 475 (86 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_pc.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def problem2_pc(testfile, outfile=None, k=None):\n",
    "    \n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    test['R2'] = 0.0\n",
    "    \n",
    "    # create rng, a list of users to solve for\n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    # loop through each user\n",
    "    for i in range(rng[0], rng[1]):\n",
    "        \n",
    "        # separate known and unknown ratings\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        # calculate USER similarity by comparing each rating R in 'known' against every other movie rating\n",
    "        user_sim = train.apply(lambda x: pea_cor(known.R.values, x[known.M].values), axis=1)\n",
    "        \n",
    "        avg_rating = np.mean(known.R)\n",
    "        \n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rs, rr = remove_zeros(user_sim, train[r.M])\n",
    "            rr = rr - np.mean(rr)\n",
    "            knn = pd.DataFrame({'S':rs, 'R':rr}).sort_values(by='S', ascending=False)\n",
    "            knn = knn.iloc[:k]\n",
    "            r.R = round_result(avg_rating + weighted_avg(knn['S'], knn['R'], True))\n",
    "            \n",
    "            results = results.append(r, ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "    \n",
    "    # remove 0's and 6's\n",
    "    count_col(results, [0,6], 'R')\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results[['U','M','R']].astype(int), outfile)\n",
    "        \n",
    "    return results\n",
    "\n",
    "test04 = problem2_pc('test5.txt', 'result5_pc.txt')\n",
    "test05 = problem2_pc('test10.txt', 'result10_pc.txt')\n",
    "test06 = problem2_pc('test20.txt', 'result20_pc.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Pearson Correlation w/ Inverse User Frequency\n",
    "> Inverse user frequency uses a log function to apply a larger weight to \"unpopular\" movies, or movies with less ratings. The assumnption is that popular movies will all receive similar positive ratings, so less popular movies should have a larger impact on estimated ratings.\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "iuf(j) = \\log{(\\frac{m}{m_j})}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 225 (140 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 275 (7 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_pciuf.txt\n",
      "\n",
      "User 325 (12 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 375 (19 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_pciuf.txt\n",
      "\n",
      "User 425 (94 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 475 (86 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_pciuf.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def problem2_pciuf(testfile, outfile=None, k=None):\n",
    "    \n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    \n",
    "    # compute iuf\n",
    "    m = len(train)\n",
    "    iuf = []\n",
    "    for i,c in train.iteritems():\n",
    "        mj = c[c!=0].count()\n",
    "        iuf.append(np.log(m/mj) if mj else 0.0)\n",
    "    train_iuf = train*iuf\n",
    "    \n",
    "    # create rng, a list of users to solve for\n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    # loop through each user\n",
    "    for i in range(rng[0], rng[1]):\n",
    "        \n",
    "        # separate known and unknown ratings\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        # calculate USER similarity by comparing each rating R in 'known' against every other movie rating\n",
    "        user_sim = train_iuf.apply(lambda x: pea_cor(known.R.values, x[known.M].values), axis=1)\n",
    "        \n",
    "        avg_rating = np.mean(known.R)\n",
    "        \n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rs, rr = remove_zeros(user_sim, train[r.M])\n",
    "            rr = rr - np.mean(rr)\n",
    "            knn = pd.DataFrame({'S':rs, 'R':rr}).sort_values(by='S', ascending=False)\n",
    "            knn = knn.iloc[:k]\n",
    "            r.R = round_result(avg_rating + weighted_avg(knn['S'], knn['R'], True))\n",
    "            \n",
    "            results = results.append(r, ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "    \n",
    "    # remove 0's and 6's\n",
    "    count_col(results, [0,6], 'R')\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results, outfile)\n",
    "        \n",
    "    return results\n",
    "\n",
    "test07 = problem2_pciuf('test5.txt', 'result5_pciuf.txt')\n",
    "test08 = problem2_pciuf('test10.txt', 'result10_pciuf.txt')\n",
    "test09 = problem2_pciuf('test20.txt', 'result20_pciuf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Pearson Correlation w/ Case Modification\n",
    "> Case modification applies an exponent to each value in the similarity matrix after it is generated. I used the common value of 2.5, which will have little effect on high similarity values, while greatly reducing smaller similarity values.\n",
    ">\n",
    "> $\n",
    "\\begin{align}\n",
    "w' = w \\cdot |w^\\rho|\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 225 (140 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 275 (7 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_pccm.txt\n",
      "\n",
      "User 325 (12 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 375 (19 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_pccm.txt\n",
      "\n",
      "User 425 (94 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 475 (86 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_pccm.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def problem2_pccm(testfile, outfile=None, k=None, p=2.5):\n",
    "    \n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    test['R2'] = 0.0\n",
    "    \n",
    "    # create rng, a list of users to solve for\n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    # loop through each user\n",
    "    for i in range(rng[0], rng[1]):\n",
    "        \n",
    "        # separate known and unknown ratings\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        # calculate USER similarity by comparing each rating R in 'known' against every other movie rating\n",
    "        user_sim = train.apply(lambda x: pea_cor(known.R.values, x[known.M].values), axis=1)\n",
    "        \n",
    "        # apply case modification\n",
    "        user_sim = user_sim * (user_sim ** p)\n",
    "        \n",
    "        avg_rating = np.mean(known.R)\n",
    "        \n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rs, rr = remove_zeros(user_sim, train[r.M])\n",
    "            rr = rr - np.mean(rr)\n",
    "            knn = pd.DataFrame({'S':rs, 'R':rr}).sort_values(by='S', ascending=False)\n",
    "            knn = knn.iloc[:k]\n",
    "            r.R = round_result(avg_rating + weighted_avg(knn['S'], knn['R'], True))\n",
    "            \n",
    "            results = results.append(r, ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "    \n",
    "    # remove 0's and 6's\n",
    "    count_col(results, [0,6], 'R')\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results[['U','M','R']].astype(int), outfile)\n",
    "        \n",
    "    return results\n",
    "\n",
    "test10 = problem2_pccm('test5.txt', 'result5_pccm.txt')\n",
    "test11 = problem2_pccm('test10.txt', 'result10_pccm.txt')\n",
    "test12 = problem2_pccm('test20.txt', 'result20_pccm.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Function:\n",
    "> Here I implemented a basic item-based collaborative filtering algorithm. This function simply generates a similarity matrix between different items (movies) rather than between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 iterations...\n",
      "Completed 2000 iterations...\n",
      "Completed 3000 iterations...\n",
      "Completed 4000 iterations...\n",
      "Completed 5000 iterations...\n",
      "Completed 6000 iterations...\n",
      "Completed 7000 iterations...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_ibcf.txt\n",
      "\n",
      "Completed 1000 iterations...\n",
      "Completed 2000 iterations...\n",
      "Completed 3000 iterations...\n",
      "Completed 4000 iterations...\n",
      "Completed 5000 iterations...\n",
      "Completed 6000 iterations...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_ibcf.txt\n",
      "\n",
      "Completed 1000 iterations...\n",
      "Completed 2000 iterations...\n",
      "Completed 3000 iterations...\n",
      "Completed 4000 iterations...\n",
      "Completed 5000 iterations...\n",
      "Completed 6000 iterations...\n",
      "Completed 7000 iterations...\n",
      "Completed 8000 iterations...\n",
      "Completed 9000 iterations...\n",
      "Completed 10000 iterations...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_ibcf.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def problem3(testfile, outfile=None, k=None, t=0.8):\n",
    "    \n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    test['R2'] = 0.0\n",
    "    \n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    unknown = test[test.R==0]\n",
    "    ct = 0\n",
    "    \n",
    "    # iterate through all unranked movies\n",
    "    for i,r in unknown.iterrows():\n",
    "        known = test[(test.R!=0) & (test.U==r.U)]\n",
    "        \n",
    "        # generate and sort the ITEM similarity matrix (using cos_sim)\n",
    "        item_sim = train[known.M].apply(lambda x: cos_sim(train[r.M], x), axis=0)\n",
    "        rs, rr = remove_zeros(item_sim, known.R)\n",
    "        knn = pd.DataFrame({'S':rs, 'R':rr}).sort_values(by='S', ascending=False)\n",
    "        knn = knn.iloc[:k]\n",
    "        \n",
    "        # compute ratings\n",
    "        r.R2 = weighted_avg(knn['S'], knn['R'])\n",
    "        r.R = round_result(r.R2)\n",
    "             \n",
    "        results = results.append(r, ignore_index=True)\n",
    "        \n",
    "        # progress update\n",
    "        ct = ct + 1\n",
    "        if ct%1000 == 0:\n",
    "            print(\"Completed {} iterations...\".format(ct))\n",
    "            \n",
    "    count_col(results, [0,6], 'R')\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results[['U','M','R']].astype(int), outfile)\n",
    "    \n",
    "    return results\n",
    "\n",
    "test13 = problem3('test5.txt', 'result5_ibcf.txt')\n",
    "test14 = problem3('test10.txt', 'result10_ibcf.txt')\n",
    "test15 = problem3('test20.txt', 'result20_ibcf.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Function:\n",
    "> This is a personal algorithm I created to try to achieve better MAE than the previous methods. In this method, I used cosine similarity as a foundation, since I achieved the best results with it so far. Then, I took all cases where the similarity matrix was empty, and rather than fill with 0 (which gets constrained to 1), I filled these values with the average movie rating among all users. Failing this, I simply used the mean value of all ratings, 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 225 (140 predictions)...\n",
      "User 250 (364 predictions)...\n",
      "User 275 (7 predictions)...\n",
      "User 300 (141 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result5_me.txt\n",
      "\n",
      "User 325 (12 predictions)...\n",
      "User 350 (28 predictions)...\n",
      "User 375 (19 predictions)...\n",
      "User 400 (41 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result10_me.txt\n",
      "\n",
      "User 425 (94 predictions)...\n",
      "User 450 (130 predictions)...\n",
      "User 475 (86 predictions)...\n",
      "User 500 (33 predictions)...\n",
      "! 0 appears 0 times in column R\n",
      "! 6 appears 0 times in column R\n",
      "> Results written to result20_me.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def problem4(testfile, outfile=None, k=None, t=0.8):\n",
    "    \n",
    "    # fetch training/testing data\n",
    "    train = fetch_train()\n",
    "    test = fetch_test(testfile)\n",
    "    \n",
    "    # create rng, a list of users to solve for\n",
    "    rng = (test.U.min(), test.U.max()+1)\n",
    "    results = pd.DataFrame(columns=test.columns)\n",
    "    \n",
    "    # loop through each user\n",
    "    for i in range(rng[0], rng[1]):\n",
    "        \n",
    "        # separate known and unknown ratings\n",
    "        ratings = test[test.U==i]\n",
    "        known = ratings[ratings.R!=0]\n",
    "        unknown = ratings[ratings.R==0]\n",
    "        \n",
    "        # calculate USER similarity by comparing each rating R in 'known' against every other movie rating\n",
    "        user_sim = train.apply(lambda x: cos_sim(known.R.values, x[known.M].values), axis=1)\n",
    "\n",
    "        # rating prediction\n",
    "        for j, r in unknown.iterrows():\n",
    "            rs, rr = remove_zeros(user_sim, train[r.M])\n",
    "            knn = pd.DataFrame({'S':rs, 'R':rr}).sort_values(by='S', ascending=False)\n",
    "            knn = knn.iloc[:k]\n",
    "            r.R = round(weighted_avg(knn['S'], knn['R']))\n",
    "            \n",
    "            if r.R == 0:\n",
    "                all_rat = train[r.M]\n",
    "                r.R = round(np.mean(all_rat[all_rat>0])) if (all_rat != 0).any() else 3\n",
    "            \n",
    "            results = results.append(r, ignore_index=True)\n",
    "        \n",
    "        # print update\n",
    "        if (i%UPDATE_INT == 0):\n",
    "            print(\"User {} ({} predictions)...\".format(i, len(unknown.M)))\n",
    "    \n",
    "    count_col(results, [0,6], 'R')\n",
    "        \n",
    "    if outfile:\n",
    "        write_test(results[['U','M','R']].astype(int), outfile)\n",
    "        \n",
    "    return results\n",
    "\n",
    "test16 = problem4('test5.txt', 'result5_me.txt')\n",
    "test17 = problem4('test10.txt', 'result10_me.txt')\n",
    "test18 = problem4('test20.txt', 'result20_me.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIN: 9423572820721098"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
